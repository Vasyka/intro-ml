{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf28d564-cb2e-45c6-823d-cdb1aee8db31",
   "metadata": {},
   "source": [
    "## Введение в машинное обучение\n",
    "\n",
    "## НИУ ВШЭ\n",
    "\n",
    "### Домашнее задание №3\n",
    "\n",
    "### О задании\n",
    "\n",
    "В этом домашнем задании вы реализуете решающее дерево и попрактикуетесь в решении задач классификации.\n",
    "\n",
    "### Оценивание и штрафы\n",
    "\n",
    "Оценка за ДЗ вычисляется по следующей формуле:\n",
    "\n",
    "$$\n",
    "\\text{points} \\times 10 / 14,\n",
    "$$\n",
    "\n",
    "где points — количество баллов за обязательную часть, которое вы набрали.\n",
    "\n",
    "__Внимание!__ Домашнее задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов.\n",
    "\n",
    "Импортируйте все нужные вам функции ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "73f14fa5-2ded-4be7-a06f-0741f5778643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from typing import Iterable, List, Tuple, Union\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (11, 6.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02cfebe-1e68-40f6-bf2f-173e37115aea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ef351eb-dd7f-45bc-9b37-db9683334f90",
   "metadata": {},
   "source": [
    "# Решающее дерево своими руками (8 баллов + бонус)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43e40c7-8b96-4346-8024-cce214e49295",
   "metadata": {},
   "source": [
    "В этой части для тестирования будем использовать датасет breast cancer. По предоставленной информации о ядрах клеток нужно предсказать присутствуют ли на изображении раковые клетки (класс 0) или нет (класс 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4049d153-c860-47fd-aabc-fc9bb3627cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>mean area cat</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>12.89</td>\n",
       "      <td>13.12</td>\n",
       "      <td>81.89</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.06955</td>\n",
       "      <td>0.03729</td>\n",
       "      <td>0.02260</td>\n",
       "      <td>0.01171</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>0.05581</td>\n",
       "      <td>...</td>\n",
       "      <td>87.40</td>\n",
       "      <td>577.0</td>\n",
       "      <td>0.09616</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>0.1186</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.06915</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>13.40</td>\n",
       "      <td>20.52</td>\n",
       "      <td>88.64</td>\n",
       "      <td>556.7</td>\n",
       "      <td>0.11060</td>\n",
       "      <td>0.14690</td>\n",
       "      <td>0.14450</td>\n",
       "      <td>0.08172</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.07325</td>\n",
       "      <td>...</td>\n",
       "      <td>113.30</td>\n",
       "      <td>844.4</td>\n",
       "      <td>0.15740</td>\n",
       "      <td>0.3856</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.20510</td>\n",
       "      <td>0.3585</td>\n",
       "      <td>0.11090</td>\n",
       "      <td>medium</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>12.96</td>\n",
       "      <td>18.29</td>\n",
       "      <td>84.18</td>\n",
       "      <td>525.2</td>\n",
       "      <td>0.07351</td>\n",
       "      <td>0.07899</td>\n",
       "      <td>0.04057</td>\n",
       "      <td>0.01883</td>\n",
       "      <td>0.1874</td>\n",
       "      <td>0.05899</td>\n",
       "      <td>...</td>\n",
       "      <td>96.31</td>\n",
       "      <td>621.9</td>\n",
       "      <td>0.09329</td>\n",
       "      <td>0.2318</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>0.06608</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.07247</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>17.75</td>\n",
       "      <td>28.03</td>\n",
       "      <td>117.30</td>\n",
       "      <td>981.6</td>\n",
       "      <td>0.09997</td>\n",
       "      <td>0.13140</td>\n",
       "      <td>0.16980</td>\n",
       "      <td>0.08293</td>\n",
       "      <td>0.1713</td>\n",
       "      <td>0.05916</td>\n",
       "      <td>...</td>\n",
       "      <td>145.40</td>\n",
       "      <td>1437.0</td>\n",
       "      <td>0.14010</td>\n",
       "      <td>0.3762</td>\n",
       "      <td>0.6399</td>\n",
       "      <td>0.19700</td>\n",
       "      <td>0.2972</td>\n",
       "      <td>0.09075</td>\n",
       "      <td>largest</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>20.58</td>\n",
       "      <td>22.14</td>\n",
       "      <td>134.70</td>\n",
       "      <td>1290.0</td>\n",
       "      <td>0.09090</td>\n",
       "      <td>0.13480</td>\n",
       "      <td>0.16400</td>\n",
       "      <td>0.09561</td>\n",
       "      <td>0.1765</td>\n",
       "      <td>0.05024</td>\n",
       "      <td>...</td>\n",
       "      <td>158.30</td>\n",
       "      <td>1656.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.2920</td>\n",
       "      <td>0.3861</td>\n",
       "      <td>0.19200</td>\n",
       "      <td>0.2909</td>\n",
       "      <td>0.05865</td>\n",
       "      <td>largest</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "287        12.89         13.12           81.89      515.9          0.06955   \n",
       "512        13.40         20.52           88.64      556.7          0.11060   \n",
       "402        12.96         18.29           84.18      525.2          0.07351   \n",
       "446        17.75         28.03          117.30      981.6          0.09997   \n",
       "210        20.58         22.14          134.70     1290.0          0.09090   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "287           0.03729         0.02260              0.01171         0.1337   \n",
       "512           0.14690         0.14450              0.08172         0.2116   \n",
       "402           0.07899         0.04057              0.01883         0.1874   \n",
       "446           0.13140         0.16980              0.08293         0.1713   \n",
       "210           0.13480         0.16400              0.09561         0.1765   \n",
       "\n",
       "     mean fractal dimension  ...  worst perimeter  worst area  \\\n",
       "287                 0.05581  ...            87.40       577.0   \n",
       "512                 0.07325  ...           113.30       844.4   \n",
       "402                 0.05899  ...            96.31       621.9   \n",
       "446                 0.05916  ...           145.40      1437.0   \n",
       "210                 0.05024  ...           158.30      1656.0   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "287           0.09616             0.1147           0.1186   \n",
       "512           0.15740             0.3856           0.5106   \n",
       "402           0.09329             0.2318           0.1604   \n",
       "446           0.14010             0.3762           0.6399   \n",
       "210           0.11780             0.2920           0.3861   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \\\n",
       "287               0.05366          0.2309                  0.06915   \n",
       "512               0.20510          0.3585                  0.11090   \n",
       "402               0.06608          0.3207                  0.07247   \n",
       "446               0.19700          0.2972                  0.09075   \n",
       "210               0.19200          0.2909                  0.05865   \n",
       "\n",
       "     mean area cat  target  \n",
       "287         medium       1  \n",
       "512         medium       0  \n",
       "402         medium       1  \n",
       "446        largest       0  \n",
       "210        largest       0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer = load_breast_cancer()\n",
    "X = pd.DataFrame(data=breast_cancer[\"data\"], columns=breast_cancer[\"feature_names\"])\n",
    "\n",
    "# добавим искуственный категориальный признак\n",
    "X['mean area cat'] = pd.qcut(X['mean area'], 5, labels=['smallest','small','medium','big', 'largest']).astype('object') \n",
    "\n",
    "X[\"target\"] = breast_cancer[\"target\"]\n",
    "X_train, X_test = train_test_split(X, test_size=0.25, random_state=42)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc6ab8f-6c1b-448d-95f5-198cb990f8c9",
   "metadata": {},
   "source": [
    "### 1. Оцениванием качество разбиения (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94548f7b-89bc-422e-9434-6269e0199d19",
   "metadata": {},
   "source": [
    "$R_m$ - множество объектов в разбиваемой вершине, $j$ - номер признака, по которому происходит разбиение, $t$ - порог разбиения.\n",
    "\n",
    "Критерий ошибки:\n",
    "\n",
    "$$\n",
    "Q(R_m, j, t) = \\frac{|R_\\ell|}{|R_m|}H(R_\\ell) + \\frac{|R_r|}{|R_m|}H(R_r) \\to \\min_{j, t}\n",
    "$$\n",
    "\n",
    "$R_\\ell$ - множество объектов в левом поддереве, $R_r$ - множество объектов в правом поддереве.\n",
    "\n",
    "$H(R)$ - критерий информативности, с помощью которого можно оценить качество распределения целевой переменной среди объектов множества $R$.\n",
    "\n",
    "Используйте функции для подсчета значения критерия ошибки, а также для разбиения вершины из семинара:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e18c9ff-1304-4f47-9477-5f386623b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_node(R_m: np.ndarray, feature: str, t: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Split a fixed set of objects R_m with given feature name and threshold t\n",
    "    \"\"\"\n",
    "    mask = R_m[feature] <= t\n",
    "    R_l = R_m.loc[mask]\n",
    "    R_r = R_m.loc[~mask]\n",
    "    return R_l, R_r\n",
    "\n",
    "\n",
    "def q_error(R_m: np.ndarray, feature: str, t: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute error criterion for the given objects R_m, feature name and threshold t\n",
    "    \"\"\"\n",
    "    R_l, R_r = split_node(R_m, feature, t)\n",
    "    return  len(R_l) / len(R_m) * H(R_l['target']) + len(R_r) / len(R_m) * H(R_r['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3c69da-3c1a-4005-ab4f-12ad3bca1b79",
   "metadata": {},
   "source": [
    "__(0.5 балла)__ Реализуйте функцию для вычисления критерия информативности. На семинаре мы рассматривали решающее дерево для регрессии и в качестве критерия качества разбиения использовали дисперсию целевой переменной. Для классификации лучше использовать другие критерии, например энтропию:\n",
    "\n",
    "$$H(R) = -p_0\\log_{2}{p_0} -p_1\\log_{2}{p_1},$$ где $p_1$, $p_0$ — доля объектов среди $R$, которые относятся к классу 1 и 0 соответственно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4701087c-2aec-48b1-8811-5a6e931ac36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def H(y: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute entropy for vector y with classes of objects R\n",
    "        \n",
    "    \"\"\"\n",
    "    probabilities = # your code here\n",
    "\n",
    "    return entropy\n",
    "\n",
    "# Проверяем на простых примерах\n",
    "assert np.isclose(H([0,0,0,0,0,1]), 0.650022)\n",
    "assert np.isclose(H([0,0,0,0,0,0]), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fd02fe-2ac0-4529-bd71-11ce3e2cf609",
   "metadata": {},
   "source": [
    "__(0.5 балла)__ Выберите признак, который как вам кажется может быть полезен для предсказания и порог для него. Сравните значение критерия информативности для объектов выборки до разбиения и взвешенной суммы критериев информативности для объектов после разбиения ($Q(R_m,j,t)$). Какой можно сделать вывод?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c635d3d2-7d6d-4cd4-825a-b4060051280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fd66f2-d99d-4292-8210-c4cd98ad8fe3",
   "metadata": {},
   "source": [
    "### 2. Ищем наилучшее разбиение (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d5ef77-7853-4da9-8620-6dac7126ee20",
   "metadata": {},
   "source": [
    "Теперь нужно найти наилучшее разбиение множества объектов $R_m$ в данной вершине, то есть такой порог $t$ для некоторого признака, где значение критерия ошибки $Q(R_m, j, t)$ минимально.\n",
    "\n",
    "__(1 балл)__ Модифицируйте функцию *get_optimal_split* из семинара так, чтобы:\n",
    "- Не было случаев, когда в одно из поддеревьев попадает 0 объектов \n",
    "- В качестве порога использовалось среднее двух различных соседних (при сортировке) значений признака \n",
    "- При одинаковых значениях критерия ошибки выбирался минимальный сплит \n",
    "\n",
    "__(Бонусные 0.5 балла)__ Перепешите функцию так, чтобы не использовались циклы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "43b91045-938c-4c1d-b5ca-e09870e1af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_split(R_m: np.array, feature: str) -> Tuple[float, List[float]]:\n",
    "    \"\"\"\n",
    "    Find best split of objects R_m by feature and return minimal q_error (opt_q_error), best threshold (opt_threshold) and array of error criterions (Q_array)\n",
    "        \n",
    "    \"\"\"\n",
    "    Q_array = []\n",
    "    feature_values = np.unique(R_m[feature])\n",
    "    \n",
    "    for t in feature_values:\n",
    "        Q_array.append(q_error(R_m, feature, t))\n",
    "        \n",
    "    Q_array = np.nan_to_num(Q_array, nan=float(\"+inf\"))\n",
    "    \n",
    "    minimum_id = np.argmin(Q_array)\n",
    "    opt_threshold = feature_values[minimum_id]\n",
    "    opt_q_error = Q_array[minimum_id]\n",
    "    \n",
    "    return opt_threshold, opt_q_error, Q_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a04929-75e9-47ca-bc89-98e8f154e8cf",
   "metadata": {},
   "source": [
    "__(0.25 балла)__ Постройте график зависимости критерия ошибки от выбранного порога для того же признака что и в 1ом задании и отметьте точку где достигается минимум."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888597cd-d8ae-498b-a05c-e2d182f3835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdbc2bf-a279-4f95-907c-1190410eb2d5",
   "metadata": {},
   "source": [
    "__(0.75 балла)__ Найдите признак с минимальным значением критерия ошибки. Постройте на одном графике распределения значений этого признака для нулевого и первого класса (можно использовть seaborn) и добавьте прямую указывающую местоположение порога. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad63030-9b7d-4e6e-ab7e-6c9e1843946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30462445-6ecc-4799-9466-9cc828c84cab",
   "metadata": {},
   "source": [
    "### 3. Строим дерево (5 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8813289-0980-4409-a5fa-466b55fcad09",
   "metadata": {},
   "source": [
    "Теперь можно реализовать алгоритм целиком. Начинаем строить дерево с корня. В корне дерева находится вся обучающая выборка. Затем используем жадный алгоритм:\n",
    "\n",
    "0. Проверяем критерий остановки - все элементы в вершине относятся к одному классу, ни по одному признаку нельзя разбить выборку, достигнута максимальная глубина дерева и пр.\n",
    "\n",
    "1. Cреди всех признаков выбираем признак с минимальным значением критерия ошибки.\n",
    "\n",
    "2. Разбиваем выборку на две подвыборки по наилучшему порогу для этого признака и из этих подвыборок получаем две новые дочерние вершины. \n",
    "\n",
    "3. Для каждой из них рекурсивно потворяем аналогичные действия."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a21fa-134b-4044-8a8d-bdb5e00bb76e",
   "metadata": {},
   "source": [
    "__(3 балла)__ Заполните пропущенные строчки в функции __fit_node_ и реализуйте функцию __predict_node_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a155d683-d686-4b97-a6fd-61a256349060",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(\n",
    "        self, \n",
    "        feature_types: Union[List[str], np.ndarray], \n",
    "        max_depth: int = None, \n",
    "        min_samples_split: int = None, \n",
    "        min_samples_leaf: int = None\n",
    "    ) -> None:\n",
    "        \n",
    "        if np.any(list(map(lambda x: x not in ('int64', 'float64', 'object'), feature_types))):\n",
    "            raise ValueError(\"There is unknown feature type\")\n",
    "\n",
    "        # В этой переменной будем хранить узлы решающего дерева. Каждая вершина хранит в себе идентификатор того,\n",
    "        # является ли она листовой (\"terminal\" или \"nonterminal\"). Листовые вершины хранят значение класса для предсказания, \n",
    "        # нелистовые - правого и левого детей (поддеревья для продолжения процедуры предсказания)\n",
    "        self._tree = {\"depth\":0}\n",
    "        \n",
    "        # типы признаков (категориальные или числовые)\n",
    "        self._feature_types = feature_types\n",
    "        \n",
    "        # гиперпараметры дерева\n",
    "        self._max_depth = max_depth\n",
    "        self._min_samples_split = min_samples_split\n",
    "        self._min_samples_leaf = min_samples_leaf\n",
    "\n",
    "    def _fit_node(\n",
    "        self, \n",
    "        sub: pd.DataFrame, # подмножество объектов для данной вершины\n",
    "        node: dict        # словарь для хранения информации о вершине\n",
    "    ) -> None:\n",
    "        \n",
    "        # критерий остановки - проверяем что не все классы объектов в данной вершине одинаковы\n",
    "        if np.all(sub['target'] == sub['target'].iloc[0]):\n",
    "            node[\"type\"] = \"terminal\"\n",
    "            node[\"class\"] = sub['target'].iloc[0]\n",
    "            return\n",
    "        \n",
    "        \n",
    "        # ищем лучший признак для разбиения\n",
    "        feature_best, threshold_best, q_best = None, None, None\n",
    "        for feature in sub.columns[:-1]:\n",
    "            feature_type = self._feature_types[feature]\n",
    "              \n",
    "            # ищем оптимальный порог для текущего признака\n",
    "            threshold, q, q_array = get_optimal_split(sub, feature)\n",
    "            \n",
    "            \n",
    "            # your code here\n",
    "\n",
    "            \n",
    "        # выбираем класс для листовой вершины\n",
    "        if feature_best is None or node[\"depth\"] == self._max_depth:\n",
    "            node[\"type\"] = \"terminal\"\n",
    "            node[\"class\"] = Counter(sub['target']).most_common(1)[0][0]\n",
    "            return\n",
    "        \n",
    "        # записываем полученное разбиение в атрибуты класса\n",
    "        node[\"type\"] = \"nonterminal\"\n",
    "        node[\"feature_split\"] = feature_best\n",
    "        node[\"threshold\"] = threshold_best\n",
    "        sub_l, sub_r = split_node(sub, feature_best, threshold_best)\n",
    "    \n",
    "        # запускаем рекурсию\n",
    "        node[\"left_child\"], node[\"right_child\"] = {\"depth\": node[\"depth\"]+1}, {\"depth\": node[\"depth\"]+1}\n",
    "        self._fit_node(sub_l, node[\"left_child\"])\n",
    "        self._fit_node(sub_r, node[\"right_child\"])\n",
    "\n",
    "    def _predict_node(self, x: pd.Series, node: dict) -> int:\n",
    "        \"\"\"\n",
    "        Предсказание начинается с корневой вершины дерева и рекурсивно идёт в левое или правое поддерево в зависимости от значения\n",
    "        предиката на объекте. Листовая вершина возвращает предсказание.\n",
    "        :param x: pd.Series, элемент выборки\n",
    "        :param node: dict, вершина дерева\n",
    "        \"\"\"\n",
    "        # your code here\n",
    "        \n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: np.ndarray) -> None:\n",
    "        X['target'] = y\n",
    "        self._fit_node(X, self._tree)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame) -> pd.Series:\n",
    "        predicted = []\n",
    "        for ind, x in X.iterrows():\n",
    "            predicted.append(self._predict_node(x, self._tree))\n",
    "            \n",
    "        return np.array(predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b35588-169e-45f2-bd8f-5c4942abcb46",
   "metadata": {},
   "source": [
    "__(1 балл)__ Обучите решающее дерево на обучающей части датасета (исключив колонку \"mean area cat\") и сравните accuracy полученную на обучающей и тестовой части. Совпадают ли топовые признаки с минимальным значением ошибки из предпредыдущего задания с признаками по которым произошли разбиения в дереве?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16533daa-2786-463a-85b2-92d8cc0a69a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c54b572a-9d76-44e2-b6a7-08e12c23c7d0",
   "metadata": {},
   "source": [
    "__(1 балл)__ Как будет происходить разбиение в вершине дерева по категориальному признаку? Является ли оно эффективным? Исправьте одну из функций выше так, чтобы дерево не выдавало ошибку при обучении на датасете с категориальными признаками. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f527ae2-9470-4e1a-844b-9e286aeb0906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18c5cc81-cfd1-4e0a-80bc-4bdaa050e73c",
   "metadata": {},
   "source": [
    "# Практическая часть (6 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e90045-6a26-4557-adc8-583a9d326668",
   "metadata": {},
   "source": [
    "__(2 балла)__ В этом задании нужно для того же датасета обучить несколько алгоритмов с помощью кросс-валидации и сравнить их качество по ROC AUC, accuracy и f1-score. Не забудьте удалить дополнительные колонки, которые были добавлены ранее.\n",
    "\n",
    "1. Обучите и нарисуйте решающее дерево c глубиной 3. Настройте font_size или общий размер графика чтобы названия признаков были читабельны. Сравните его с деревом, которое вы написали самостоятельно. Для решающего дерева подберите оптимальный max_depth и min_samples_split по выбранной метрике.\n",
    "\n",
    "2. Обучите логистическую регрессию c L2 регуляризацией и подберите для нее наилучший параметр.\n",
    "\n",
    "3. Обучите SVM и выберите наиболее подходящее ядро и параметр регуляриации.\n",
    "\n",
    "\n",
    "Выберите метрику, по которой вы будете выбирать наилучшие параметры. Почему для этого датасета стоит сравнивать предсказания не только по значению accuracy? Что важнее для этой задачи - оптимизировать precision или recall? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc67ea7-20bf-4d32-96c3-a36103220eba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66d965b4-2b98-4caf-8c2e-3c4c3923313b",
   "metadata": {},
   "source": [
    "Теперь загрузим еще один [датасет](https://www.kaggle.com/datasets/rashmiranu/banking-dataset-classification). По данным о клиентам банка нужно предсказать будет ли клиент брать кредит на длительный срок или нет. И если да, то сотрудники банка позвонят и предложат ему кредит. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "36b4c372-4c15-4211-8a1e-fe4847b5f587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.9y</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>wed</td>\n",
       "      <td>227</td>\n",
       "      <td>4</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nov</td>\n",
       "      <td>wed</td>\n",
       "      <td>202</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>1148</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>120</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>university.degree</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jun</td>\n",
       "      <td>tue</td>\n",
       "      <td>368</td>\n",
       "      <td>2</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job   marital          education  default housing loan  \\\n",
       "0   49   blue-collar   married           basic.9y  unknown      no   no   \n",
       "1   37  entrepreneur   married  university.degree       no      no   no   \n",
       "2   78       retired   married           basic.4y       no      no   no   \n",
       "3   36        admin.   married  university.degree       no     yes   no   \n",
       "4   59       retired  divorced  university.degree       no      no   no   \n",
       "\n",
       "     contact month day_of_week  duration  campaign  pdays  previous  \\\n",
       "0   cellular   nov         wed       227         4    999         0   \n",
       "1  telephone   nov         wed       202         2    999         1   \n",
       "2   cellular   jul         mon      1148         1    999         0   \n",
       "3  telephone   may         mon       120         2    999         0   \n",
       "4   cellular   jun         tue       368         2    999         0   \n",
       "\n",
       "      poutcome    y  \n",
       "0  nonexistent   no  \n",
       "1      failure   no  \n",
       "2  nonexistent  yes  \n",
       "3  nonexistent   no  \n",
       "4  nonexistent   no  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('new_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b239c1-41e0-49f1-9bd1-e1a31cb44d64",
   "metadata": {},
   "source": [
    "__(0.5 балла)__ Изучите и подготовьте данные - проверьте типы колонок, соотношение классов, наличие пропусков (пропуски для категориальных переменных указаны как 'unknown'), повторяющихся объектов, проверьте частоты значений признаков и их смысл - возможно какие-то признаки можно удалить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a382689-a8e8-4d05-9c25-8cb1dba47347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f027816-a5a8-435c-8dae-21fce6a4a973",
   "metadata": {},
   "source": [
    "__(0.5 балла)__ Постройте графики с распределениями по каждому из категориальных признаков. Статистики должны быть выведены для обоих классов и либо расположены на одном графике, либо находиться на соседних графиках, чтобы можно было сравнить их между собой. Вам поможет plt.subplot(s) если вы используете matplotlib или продвинутые функции из seaborn, позволяющие автоматически строить сразу несколько графиков. Убедитесь что на графиках подписаны оси, все надписи читабельны и пр. Проанализируйте полученные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df5d0e2-26c4-4f69-bfd5-9af4195f0757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51519052-139b-4102-9fb8-50163f3136a8",
   "metadata": {},
   "source": [
    "__(0.5 балла)__ Проведите анализ числовых признаков - постройте попарные графики для признаков и график с корреляцией Пирсона."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87ad1a-3dde-42e6-8c4d-f368fc7440ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff9f1cc2-6a94-4b40-b0e9-73ecef475f88",
   "metadata": {},
   "source": [
    "__(0.5 балл)__ Преобразуйте категориальные признаки. Подумайте какие признаки лучше закодировать с помощью one-hot encoding, а какие с помощью label-encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f1eec8-e5e5-4b4d-9316-a70d547fe8db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41b2a98c-1f76-49f4-bfac-f77b5f1b58ff",
   "metadata": {},
   "source": [
    "__(1 балл)__ В этом датасете отношение между положительными примерами и отрицательными практически 1:8. Поэтому хорошей идеей будет сбалансировать датасет (oversampling - добавить элементы менее популярного класса на основе имеющихся или undersampling - наоборот убрать элементы более популярного класса. см. [imblearn](https://imbalanced-learn.org/stable/over_sampling.html#a-practical-guide)) или пропорционально изменить веса классов в самих моделях (параметр class_weight), а также использовать чувствительные к таким случаям метрики. \n",
    "\n",
    "Разбейте датасет на train и test, используйте параметр stratify, чтобы соотношение классов не изменилось после разбиения датасета на две части. Аналогично в дальнейшем при использовании кросс-валидации используйте версию функции сохраняющую соотношение классов (StratifiedKFold). \n",
    "\n",
    "Подберите параметры логистической регрессии и решающего дерева с помощью кросс-валидации по AUC PR (площадь под Precision-Recall кривой). Для тестовой части датасета выведите получившиеся значения AUC PR, f1-score и выведите матрицы для истинных значений и предсказаний (confusion matrix). Их можно красиво вывести с помощью seaborn.heatmap(). На какую метрику стоит больше обращать внимание - на precision или recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76245b0-9f11-4954-aa93-caa60dfeeefb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "747834e3-ad79-40dd-a00c-e227518f56c5",
   "metadata": {},
   "source": [
    "__(0.5 балла)__ Рассмотрим задачу с точки зрения прибыли для банка. Маркетинговая компания требует значительных финансовых затрат, и ее эффективность напрямую зависит от качества нашей модели. Поэтому в качестве дополнительной метрики качества разумно использовать общую прибыль банка в той или иной форме. Мы будем рассматривать очень простую модель. Пусть каждый клиент после возврата всех процентов по кредиту (и с учетом всех расходов на обслуживание) приносит банку в среднем 10000 у.е., затраты на привлечение одного клиента составляют 100 у.е. Тогда сколько составит прибыль банка (доходы - расходы) если работники банка свяжутся со всеми клиентами, которых предсказала наша лучшая модель как подходящих на тестовой части и они все согласятся открыть кредит? Сколько составят расходы на маркетинг? В данной модели мы не учитываем что кредит может быть не возвращен в срок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e6a7c0-8331-418b-b43d-3bf5aebaf0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5636b5f2-5eeb-4fd8-b9d9-ea2e816a6ae6",
   "metadata": {},
   "source": [
    "__(0.5 балла)__ Снова используйте кросс-валидацию с пятью подвыборками. Обучите логистическую регрессию и выведите пять значений прибыли, а также подсчитайте среднее значение. Постройте графики зависимости среднего значения прибыли и AUC PR от параметра регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13329c-7af2-4085-9f7f-a11c5b5febca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
